{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_Tuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "opPgETM9MRKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow.keras.initializers\n",
        "import statistics\n",
        "import tensorflow.keras\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, InputLayer\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7NgB7NjOSCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWAf6acdOJsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Datasets/all_data_imputed_v2_pca.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjnGOVEHPAdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = base_data.iloc[:, :-1]\n",
        "y = base_data.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkPSvvo9MuFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_model(dropout, neuronPct, neuronShrink):\n",
        "    # We start with some percent of 5000 starting neurons on the first hidden layer.\n",
        "    neuronCount = int(neuronPct * 5000)\n",
        "    \n",
        "    # Construct neural network\n",
        "    # kernel_initializer = tensorflow.keras.initializers.he_uniform(seed=None)\n",
        "    model = Sequential()\n",
        "\n",
        "    # So long as there would have been at least 25 neurons and fewer than 10\n",
        "    # layers, create a new layer.\n",
        "    layer = 0\n",
        "    while neuronCount>25 and layer<10:\n",
        "        # The first (0th) layer needs an input input_dim(neuronCount)\n",
        "        if layer==0:\n",
        "            model.add(Dense(neuronCount, input_dim=X.shape[1],\n",
        "                            activation=\"relu\"))\n",
        "        else:\n",
        "            model.add(Dense(neuronCount, activation=\"relu\")) \n",
        "        layer += 1\n",
        "\n",
        "        # Add dropout after each hidden layer\n",
        "        model.add(Dropout(dropout))\n",
        "\n",
        "        # Shrink neuron count for each layer\n",
        "        neuronCount = neuronCount * neuronShrink\n",
        "\n",
        "    model.add(Dense(1,activation='sigmoid')) # Output\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa2Oc6nmNo-9",
        "colab_type": "code",
        "outputId": "f3a587ff-a517-4610-daa5-37f6c1499d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "\n",
        "# Generate a model and see what the resulting structure looks like.\n",
        "model = generate_model(dropout=0.2, neuronPct=0.1, neuronShrink=0.25)\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 500)               13000     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 125)               62625     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 125)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 31)                3906      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 31)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 79,563\n",
            "Trainable params: 79,563\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhYAqMzfOzw5",
        "colab_type": "code",
        "outputId": "997b7beb-7d40-4455-b53b-5737a09d6f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def evaluate_network(dropout,lr,neuronPct,neuronShrink):\n",
        "    SPLITS = 2\n",
        "    # Splits tells us how many times it will split the data randomly and create the model\n",
        "    \n",
        "    # Bootstrap\n",
        "    boot = StratifiedShuffleSplit(n_splits=SPLITS, test_size=0.1)\n",
        "\n",
        "     # Track progress\n",
        "    mean_benchmark = []\n",
        "    epochs_needed = []\n",
        "    num = 0\n",
        "\n",
        "    # Loop through samples\n",
        "    for train, test in boot.split(X, y):\n",
        "        start_time = time.time()\n",
        "        num+=1\n",
        "\n",
        "        # Split train and test\n",
        "        x_train = X.iloc[train]\n",
        "        y_train = y.iloc[train]\n",
        "        x_test = X.loc[test]\n",
        "        y_test = y.iloc[test]\n",
        "\n",
        "        model = generate_model(dropout, neuronPct, neuronShrink)\n",
        "        model.compile(loss='binary_crossentropy', optimizer=Adam(lr=lr))\n",
        "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, \n",
        "        patience=100, verbose=0, mode='auto', restore_best_weights=True)\n",
        "\n",
        "        # Train on the bootstrap sample\n",
        "        model.fit(x_train,y_train,validation_data=(x_test,y_test),\n",
        "                  callbacks=[monitor],verbose=0,epochs=5)\n",
        "        \n",
        "        epochs = monitor.stopped_epoch\n",
        "        epochs_needed.append(epochs)\n",
        "\n",
        "        # Predict on the out of boot (validation)\n",
        "        pred = model.predict(x_test)\n",
        "\n",
        "        # Measure this bootstrap's log loss\n",
        "        # y_compare = np.argmax(y_test,axis=1) # For log loss calculation\n",
        "        score = metrics.log_loss(y_test, pred, eps= 0.0001)\n",
        "        mean_benchmark.append(score)\n",
        "        m1 = statistics.mean(mean_benchmark)\n",
        "        m2 = statistics.mean(epochs_needed)\n",
        "        mdev = statistics.pstdev(mean_benchmark)\n",
        "\n",
        "        # Record this iteration\n",
        "        time_took = time.time() - start_time\n",
        "        \n",
        "    tensorflow.keras.backend.clear_session()\n",
        "    return (-m1)\n",
        "\n",
        "print(evaluate_network(\n",
        "    dropout=0.2,\n",
        "    lr=1e-3,\n",
        "    neuronPct=0.2,\n",
        "    neuronShrink=0.2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.4268185777018235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4hsHTF-o0ju",
        "colab_type": "code",
        "outputId": "aca345b0-99fe-41ae-ed96-cc5f65c97704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "pip install bayesian-optimization"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/26/9842333adbb8f17bcb3d699400a8b1ccde0af0b6de8d07224e183728acdf/bayesian_optimization-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.3)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwahPJU2XxAD",
        "colab_type": "code",
        "outputId": "fe2fa981-2bfc-48cc-bfc7-4d61c9ff5ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "import time\n",
        "\n",
        "# Supress NaN warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category =RuntimeWarning)\n",
        "\n",
        "# Bounded region of parameter space\n",
        "pbounds = {'dropout': (0.0, 0.499),\n",
        "           'lr': (0.0, 0.1),\n",
        "           'neuronPct': (0.01, 1),\n",
        "           'neuronShrink': (0.01, 1)\n",
        "          }\n",
        "\n",
        "pboundsTest = {'dropout': (0.0, 0.15),\n",
        "           'lr': (0.05, 0.1),\n",
        "           'neuronPct': (0.01, 0.2),\n",
        "           'neuronShrink': (0.01, 0.2)\n",
        "          }\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=evaluate_network,\n",
        "    pbounds=pboundsTest,\n",
        "    verbose=2,  # verbose = 1 prints only when a maximum \n",
        "    # is observed, verbose = 0 is silent\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "optimizer.maximize(init_points=10, n_iter=100,)\n",
        "time_took = time.time() - start_time\n",
        "\n",
        "print(f\"Total runtime: {hms_string(time_took)}\")\n",
        "print(optimizer.max)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   |  dropout  |    lr     | neuronPct | neuron... |\n",
            "-------------------------------------------------------------------------\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.06255 \u001b[0m | \u001b[0m 0.08602 \u001b[0m | \u001b[0m 0.01002 \u001b[0m | \u001b[0m 0.06744 \u001b[0m |\n",
            "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.4854  \u001b[0m | \u001b[95m 0.02201 \u001b[0m | \u001b[95m 0.05462 \u001b[0m | \u001b[95m 0.04539 \u001b[0m | \u001b[95m 0.07566 \u001b[0m |\n",
            "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.05952 \u001b[0m | \u001b[0m 0.07694 \u001b[0m | \u001b[0m 0.08965 \u001b[0m | \u001b[0m 0.1402  \u001b[0m |\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.5484  \u001b[0m | \u001b[0m 0.03067 \u001b[0m | \u001b[0m 0.09391 \u001b[0m | \u001b[0m 0.0152  \u001b[0m | \u001b[0m 0.1374  \u001b[0m |\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.5507  \u001b[0m | \u001b[0m 0.0626  \u001b[0m | \u001b[0m 0.07793 \u001b[0m | \u001b[0m 0.03667 \u001b[0m | \u001b[0m 0.04764 \u001b[0m |\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.5496  \u001b[0m | \u001b[0m 0.1201  \u001b[0m | \u001b[0m 0.09841 \u001b[0m | \u001b[0m 0.06955 \u001b[0m | \u001b[0m 0.1415  \u001b[0m |\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.5528  \u001b[0m | \u001b[0m 0.1315  \u001b[0m | \u001b[0m 0.09473 \u001b[0m | \u001b[0m 0.02616 \u001b[0m | \u001b[0m 0.01742 \u001b[0m |\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.5497  \u001b[0m | \u001b[0m 0.02547 \u001b[0m | \u001b[0m 0.09391 \u001b[0m | \u001b[0m 0.02869 \u001b[0m | \u001b[0m 0.09001 \u001b[0m |\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.5504  \u001b[0m | \u001b[0m 0.1437  \u001b[0m | \u001b[0m 0.07666 \u001b[0m | \u001b[0m 0.1415  \u001b[0m | \u001b[0m 0.06995 \u001b[0m |\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.5483  \u001b[0m | \u001b[0m 0.103   \u001b[0m | \u001b[0m 0.09173 \u001b[0m | \u001b[0m 0.01347 \u001b[0m | \u001b[0m 0.1525  \u001b[0m |\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.548   \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m-0.4264  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 0.2     \u001b[0m | \u001b[95m 0.01    \u001b[0m |\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.5487  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.5488  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.09677 \u001b[0m |\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.4301  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.5054  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.5533  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.5485  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.5525  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.4296  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.1212  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.4314  \u001b[0m | \u001b[0m 0.01543 \u001b[0m | \u001b[0m 0.05396 \u001b[0m | \u001b[0m 0.04    \u001b[0m | \u001b[0m 0.07161 \u001b[0m |\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.5496  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.5495  \u001b[0m | \u001b[0m 0.03511 \u001b[0m | \u001b[0m 0.07235 \u001b[0m | \u001b[0m 0.1145  \u001b[0m | \u001b[0m 0.1903  \u001b[0m |\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[95m 25      \u001b[0m | \u001b[95m-0.4244  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 0.0974  \u001b[0m |\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.09561 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.117   \u001b[0m |\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.5494  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.5487  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.1108  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.548   \u001b[0m | \u001b[0m 0.05967 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.5483  \u001b[0m | \u001b[0m 0.1227  \u001b[0m | \u001b[0m 0.05818 \u001b[0m | \u001b[0m 0.01286 \u001b[0m | \u001b[0m 0.04059 \u001b[0m |\n",
            "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.5518  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.4876  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.05232 \u001b[0m | \u001b[0m 0.03313 \u001b[0m |\n",
            "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.5507  \u001b[0m | \u001b[0m 0.06933 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.1647  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.5514  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.5491  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.5517  \u001b[0m | \u001b[0m 0.07932 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.05333 \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.5499  \u001b[0m | \u001b[0m 0.02384 \u001b[0m | \u001b[0m 0.05675 \u001b[0m | \u001b[0m 0.0511  \u001b[0m | \u001b[0m 0.0728  \u001b[0m |\n",
            "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.5483  \u001b[0m | \u001b[0m 0.07327 \u001b[0m | \u001b[0m 0.05321 \u001b[0m | \u001b[0m 0.07263 \u001b[0m | \u001b[0m 0.1316  \u001b[0m |\n",
            "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.549   \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.115   \u001b[0m |\n",
            "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.5484  \u001b[0m | \u001b[0m 0.09826 \u001b[0m | \u001b[0m 0.06089 \u001b[0m | \u001b[0m 0.1435  \u001b[0m | \u001b[0m 0.1823  \u001b[0m |\n",
            "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.5504  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.0968  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.5493  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.5507  \u001b[0m | \u001b[0m 0.05395 \u001b[0m | \u001b[0m 0.07535 \u001b[0m | \u001b[0m 0.1477  \u001b[0m | \u001b[0m 0.109   \u001b[0m |\n",
            "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.5024  \u001b[0m | \u001b[0m 0.0664  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.548   \u001b[0m | \u001b[0m 0.000343\u001b[0m | \u001b[0m 0.05353 \u001b[0m | \u001b[0m 0.05851 \u001b[0m | \u001b[0m 0.1718  \u001b[0m |\n",
            "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.5159  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.1163  \u001b[0m |\n",
            "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.5509  \u001b[0m | \u001b[0m 0.05252 \u001b[0m | \u001b[0m 0.09715 \u001b[0m | \u001b[0m 0.08208 \u001b[0m | \u001b[0m 0.06498 \u001b[0m |\n",
            "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.5519  \u001b[0m | \u001b[0m 0.09388 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1159  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.5477  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.121   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.5488  \u001b[0m | \u001b[0m 0.06321 \u001b[0m | \u001b[0m 0.0709  \u001b[0m | \u001b[0m 0.1667  \u001b[0m | \u001b[0m 0.07801 \u001b[0m |\n",
            "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.4252  \u001b[0m | \u001b[0m 0.06402 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.5498  \u001b[0m | \u001b[0m 0.1485  \u001b[0m | \u001b[0m 0.0822  \u001b[0m | \u001b[0m 0.02668 \u001b[0m | \u001b[0m 0.02342 \u001b[0m |\n",
            "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.5492  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.1117  \u001b[0m |\n",
            "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.5479  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1476  \u001b[0m | \u001b[0m 0.1412  \u001b[0m |\n",
            "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.5539  \u001b[0m | \u001b[0m 0.05702 \u001b[0m | \u001b[0m 0.09242 \u001b[0m | \u001b[0m 0.08808 \u001b[0m | \u001b[0m 0.08084 \u001b[0m |\n",
            "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.4853  \u001b[0m | \u001b[0m 0.01252 \u001b[0m | \u001b[0m 0.05382 \u001b[0m | \u001b[0m 0.01229 \u001b[0m | \u001b[0m 0.05544 \u001b[0m |\n",
            "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.5482  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.07189 \u001b[0m | \u001b[0m 0.07287 \u001b[0m |\n",
            "| \u001b[95m 58      \u001b[0m | \u001b[95m-0.4235  \u001b[0m | \u001b[95m 0.06419 \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 0.1346  \u001b[0m |\n",
            "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.5482  \u001b[0m | \u001b[0m 0.04298 \u001b[0m | \u001b[0m 0.05519 \u001b[0m | \u001b[0m 0.1722  \u001b[0m | \u001b[0m 0.03682 \u001b[0m |\n",
            "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1309  \u001b[0m | \u001b[0m 0.1497  \u001b[0m |\n",
            "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.5514  \u001b[0m | \u001b[0m 0.06976 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1603  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.5501  \u001b[0m | \u001b[0m 0.07574 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.5491  \u001b[0m | \u001b[0m 0.09454 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1326  \u001b[0m | \u001b[0m 0.09346 \u001b[0m |\n",
            "| \u001b[95m 64      \u001b[0m | \u001b[95m-0.4187  \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 0.04188 \u001b[0m | \u001b[95m 0.09892 \u001b[0m |\n",
            "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.5515  \u001b[0m | \u001b[0m 0.02385 \u001b[0m | \u001b[0m 0.07392 \u001b[0m | \u001b[0m 0.1063  \u001b[0m | \u001b[0m 0.03302 \u001b[0m |\n",
            "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.5483  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.09651 \u001b[0m | \u001b[0m 0.1193  \u001b[0m |\n",
            "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.548   \u001b[0m | \u001b[0m 0.07599 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.05881 \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.549   \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.114   \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.5494  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.08618 \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.5502  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.08956 \u001b[0m |\n",
            "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.5519  \u001b[0m | \u001b[0m 0.1199  \u001b[0m | \u001b[0m 0.0636  \u001b[0m | \u001b[0m 0.1427  \u001b[0m | \u001b[0m 0.09434 \u001b[0m |\n",
            "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.5482  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.07667 \u001b[0m |\n",
            "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.5482  \u001b[0m | \u001b[0m 0.05024 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.141   \u001b[0m |\n",
            "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.4318  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.163   \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.4429  \u001b[0m | \u001b[0m 0.02767 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01824 \u001b[0m | \u001b[0m 0.1044  \u001b[0m |\n",
            "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.5503  \u001b[0m | \u001b[0m 0.08146 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.07067 \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.5489  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.1383  \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.5491  \u001b[0m | \u001b[0m 0.08549 \u001b[0m | \u001b[0m 0.05174 \u001b[0m | \u001b[0m 0.1693  \u001b[0m | \u001b[0m 0.1127  \u001b[0m |\n",
            "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.5075  \u001b[0m | \u001b[0m 0.09651 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.1065  \u001b[0m |\n",
            "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.5481  \u001b[0m | \u001b[0m 0.143   \u001b[0m | \u001b[0m 0.08831 \u001b[0m | \u001b[0m 0.1999  \u001b[0m | \u001b[0m 0.07391 \u001b[0m |\n",
            "| \u001b[0m 81      \u001b[0m | \u001b[0m-0.5328  \u001b[0m | \u001b[0m 0.04438 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.1711  \u001b[0m |\n",
            "| \u001b[0m 82      \u001b[0m | \u001b[0m-0.4839  \u001b[0m | \u001b[0m 0.1001  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 83      \u001b[0m | \u001b[0m-0.5481  \u001b[0m | \u001b[0m 0.07909 \u001b[0m | \u001b[0m 0.0904  \u001b[0m | \u001b[0m 0.1601  \u001b[0m | \u001b[0m 0.1322  \u001b[0m |\n",
            "| \u001b[0m 84      \u001b[0m | \u001b[0m-0.5505  \u001b[0m | \u001b[0m 0.06154 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 85      \u001b[0m | \u001b[0m-0.551   \u001b[0m | \u001b[0m 0.06539 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 86      \u001b[0m | \u001b[0m-0.5485  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1506  \u001b[0m | \u001b[0m 0.06816 \u001b[0m |\n",
            "| \u001b[0m 87      \u001b[0m | \u001b[0m-0.4903  \u001b[0m | \u001b[0m 0.00306 \u001b[0m | \u001b[0m 0.05055 \u001b[0m | \u001b[0m 0.02998 \u001b[0m | \u001b[0m 0.08519 \u001b[0m |\n",
            "| \u001b[0m 88      \u001b[0m | \u001b[0m-0.5506  \u001b[0m | \u001b[0m 0.09062 \u001b[0m | \u001b[0m 0.0845  \u001b[0m | \u001b[0m 0.1339  \u001b[0m | \u001b[0m 0.08887 \u001b[0m |\n",
            "| \u001b[0m 89      \u001b[0m | \u001b[0m-0.5484  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.1121  \u001b[0m | \u001b[0m 0.1264  \u001b[0m |\n",
            "| \u001b[0m 90      \u001b[0m | \u001b[0m-0.5483  \u001b[0m | \u001b[0m 0.04135 \u001b[0m | \u001b[0m 0.06965 \u001b[0m | \u001b[0m 0.118   \u001b[0m | \u001b[0m 0.03273 \u001b[0m |\n",
            "| \u001b[0m 91      \u001b[0m | \u001b[0m-0.4197  \u001b[0m | \u001b[0m 0.02639 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.03989 \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 92      \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.06558 \u001b[0m | \u001b[0m 0.1285  \u001b[0m |\n",
            "| \u001b[0m 93      \u001b[0m | \u001b[0m-0.5129  \u001b[0m | \u001b[0m 0.1118  \u001b[0m | \u001b[0m 0.0559  \u001b[0m | \u001b[0m 0.01205 \u001b[0m | \u001b[0m 0.122   \u001b[0m |\n",
            "| \u001b[0m 94      \u001b[0m | \u001b[0m-0.4901  \u001b[0m | \u001b[0m 0.000415\u001b[0m | \u001b[0m 0.05674 \u001b[0m | \u001b[0m 0.01219 \u001b[0m | \u001b[0m 0.1284  \u001b[0m |\n",
            "| \u001b[0m 95      \u001b[0m | \u001b[0m-0.5527  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.06011 \u001b[0m | \u001b[0m 0.06233 \u001b[0m |\n",
            "| \u001b[0m 96      \u001b[0m | \u001b[0m-0.5485  \u001b[0m | \u001b[0m 0.03576 \u001b[0m | \u001b[0m 0.09766 \u001b[0m | \u001b[0m 0.1944  \u001b[0m | \u001b[0m 0.1124  \u001b[0m |\n",
            "| \u001b[0m 97      \u001b[0m | \u001b[0m-0.5486  \u001b[0m | \u001b[0m 0.08134 \u001b[0m | \u001b[0m 0.08135 \u001b[0m | \u001b[0m 0.1046  \u001b[0m | \u001b[0m 0.04471 \u001b[0m |\n",
            "| \u001b[0m 98      \u001b[0m | \u001b[0m-0.5517  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.1002  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 99      \u001b[0m | \u001b[0m-0.548   \u001b[0m | \u001b[0m 0.09408 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 100     \u001b[0m | \u001b[0m-0.5518  \u001b[0m | \u001b[0m 0.04088 \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.06562 \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 101     \u001b[0m | \u001b[0m-0.5482  \u001b[0m | \u001b[0m 0.0963  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.04793 \u001b[0m |\n",
            "| \u001b[0m 102     \u001b[0m | \u001b[0m-0.5483  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.05307 \u001b[0m | \u001b[0m 0.1662  \u001b[0m |\n",
            "| \u001b[0m 103     \u001b[0m | \u001b[0m-0.5487  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05019 \u001b[0m | \u001b[0m 0.1472  \u001b[0m | \u001b[0m 0.1508  \u001b[0m |\n",
            "| \u001b[0m 104     \u001b[0m | \u001b[0m-0.5511  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.1519  \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 105     \u001b[0m | \u001b[0m-0.5488  \u001b[0m | \u001b[0m 0.07466 \u001b[0m | \u001b[0m 0.06267 \u001b[0m | \u001b[0m 0.1283  \u001b[0m | \u001b[0m 0.1669  \u001b[0m |\n",
            "| \u001b[0m 106     \u001b[0m | \u001b[0m-0.5489  \u001b[0m | \u001b[0m 0.03582 \u001b[0m | \u001b[0m 0.06531 \u001b[0m | \u001b[0m 0.1011  \u001b[0m | \u001b[0m 0.03445 \u001b[0m |\n",
            "| \u001b[0m 107     \u001b[0m | \u001b[0m-0.5487  \u001b[0m | \u001b[0m 0.15    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.05972 \u001b[0m | \u001b[0m 0.2     \u001b[0m |\n",
            "| \u001b[0m 108     \u001b[0m | \u001b[0m-0.5485  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.04581 \u001b[0m |\n",
            "| \u001b[0m 109     \u001b[0m | \u001b[0m-0.5505  \u001b[0m | \u001b[0m 0.04205 \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 0.2     \u001b[0m | \u001b[0m 0.01    \u001b[0m |\n",
            "| \u001b[0m 110     \u001b[0m | \u001b[0m-0.5487  \u001b[0m | \u001b[0m 0.1474  \u001b[0m | \u001b[0m 0.09828 \u001b[0m | \u001b[0m 0.1992  \u001b[0m | \u001b[0m 0.144   \u001b[0m |\n",
            "=========================================================================\n",
            "Total runtime: 2:32:31.96\n",
            "{'target': -0.41874351681192545, 'params': {'dropout': 0.0, 'lr': 0.05, 'neuronPct': 0.041881484018459855, 'neuronShrink': 0.0989186632103514}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}